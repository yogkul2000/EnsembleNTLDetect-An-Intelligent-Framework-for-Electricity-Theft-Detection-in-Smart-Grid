{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackedAutoEncoder + ConditionalGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbbI7o-ReqVE"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import seaborn as sn \n",
        "from seaborn import distplot\n",
        "from seaborn import heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from math import isinf \n",
        "from scipy.interpolate import interp1d\n",
        "from numpy import array, zeros, full, argmin, inf, ndim\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "import statistics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier as RB\n",
        "#from sklearn.decomposition import KernelPCA\n",
        "#from imblearn.over_sampling import SMOTE as SM\n",
        "from sklearn.ensemble import RandomForestClassifier as RF,GradientBoostingRegressor as GB,ExtraTreesClassifier as ET\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.neural_network import MLPClassifier as MP\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout, Input, BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import History \n",
        "history = History()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,Activation,Layer,Lambda\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "\n",
        " \n",
        "# Scikit-Learn imports\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpcSmv8Dew2f"
      },
      "source": [
        "x_train,x_test,y_train,y_test= train_test_split(X_res, y_res,test_size = 0.5, random_state = 0) #try for test_size = 0.2, 0.3, 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7prlTSoBfEpi"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdI5IoDpfIJe"
      },
      "source": [
        "input_data = Input(shape=(1034,))#0\n",
        "encoded = Dense(512, activation='relu')(input_data)#1\n",
        "encoded = BatchNormalization()(encoded)#2\n",
        "encoded = Dense(256, activation='relu')(encoded)#3\n",
        "encoded = BatchNormalization()(encoded)#4\n",
        "encoded = Dense(128, activation='relu')(encoded)#5\n",
        "encoded = BatchNormalization()(encoded)#6\n",
        "\n",
        "decoded = Dense(256, activation='sigmoid')(encoded)#7\n",
        "decoded = BatchNormalization()(decoded)#8\n",
        "decoded = Dense(512, activation='sigmoid')(decoded)#9\n",
        "decoded = BatchNormalization()(decoded)#10\n",
        "decoded = Dense(1034, activation='sigmoid')(decoded)#11\n",
        "\n",
        "#del stackencoder\n",
        "stackautoencoder = Model(input_data, decoded)\n",
        "stackautoencoder.compile(loss=\"mse\",optimizer='Adam')\n",
        "stackautoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs7tLoyIfJ_E"
      },
      "source": [
        "#Autoencoder1\n",
        "input_data1 = Input(shape=(1034,))#0\n",
        "encoded1 = Dense(512, activation='relu')(input_data1)#1\n",
        "encoded1 = BatchNormalization()(encoded1)#2\n",
        "decoded1 = Dense(1034, activation='sigmoid')(encoded1)#11\n",
        "\n",
        "autoencoder1 = Model(input_data1, decoded1)\n",
        "encoder1 = Model(input_data1, encoded1)\n",
        "\n",
        "#Autoencoder2\n",
        "input_data2 = Input(shape=(512,))\n",
        "encoded2 = Dense(256, activation='relu')(input_data2)#3\n",
        "encoded2 = BatchNormalization()(encoded2)#4\n",
        "decoded2 = Dense(512, activation='relu')(encoded2)#9\n",
        "decoded2 = BatchNormalization()(decoded2)#10\n",
        "\n",
        "autoencoder2 = Model(input_data2, decoded2)\n",
        "encoder2 = Model(input_data2, encoded2)\n",
        "\n",
        "#Autoencoder3\n",
        "input_data3 = Input(shape=(256,))\n",
        "encoded3 = Dense(128, activation='relu')(input_data3)#5\n",
        "encoded3 = BatchNormalization()(encoded3)#6\n",
        "decoded3 = Dense(256, activation='relu')(encoded3)#7\n",
        "decoded3 = BatchNormalization()(decoded3)#8\n",
        "\n",
        "autoencoder3 = Model(input_data3, decoded3)\n",
        "encoder3 = Model(input_data3, encoded3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ01WPP6fMmd"
      },
      "source": [
        "autoencoder1.compile(loss=\"mse\",optimizer='Adam')\n",
        "autoencoder2.compile(loss=\"mse\",optimizer='Adam')\n",
        "autoencoder3.compile(loss=\"mse\",optimizer='Adam')\n",
        "\n",
        "encoder1.compile(loss=\"mse\",optimizer='Adam')\n",
        "encoder2.compile(loss=\"mse\",optimizer='Adam')\n",
        "encoder3.compile(loss=\"mse\",optimizer='Adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGO9LdF5fOBS"
      },
      "source": [
        "history1 = autoencoder1.fit(x_train, x_train,epochs=200, batch_size=512,shuffle=True,validation_split = 0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc5XCXqffQIB"
      },
      "source": [
        "plt.plot(history1.history['loss'])\n",
        "plt.plot(history1.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.savefig('stackAE1_model_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXDd2QC-fR1B"
      },
      "source": [
        "first_layer_code = encoder1.predict(x_train)\n",
        "print(first_layer_code.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOWdA8Y8fTAH"
      },
      "source": [
        "history2 = autoencoder2.fit(first_layer_code, first_layer_code,epochs=200,batch_size=512,shuffle=True, validation_split = 0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Rh152OfUUO"
      },
      "source": [
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.savefig('stackAE2_model_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tyDbzpMfV6r"
      },
      "source": [
        "second_layer_code = encoder2.predict(first_layer_code)\n",
        "print(first_layer_code.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdjLHZkWfXb9"
      },
      "source": [
        "history3 = autoencoder3.fit(second_layer_code, second_layer_code,epochs=800,batch_size=512,shuffle=True,validation_split = 0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqppPZnVfY_F"
      },
      "source": [
        "plt.plot(history3.history['loss'])\n",
        "plt.plot(history3.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.savefig('stackAE3_model_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JknL0917fbz1"
      },
      "source": [
        "plt.plot(history1.history['loss'],'k',label='AE1 loss')\n",
        "plt.plot(history1.history['val_loss'],'g',label='AE1 val loss')\n",
        "plt.plot(history2.history['loss'],'y',label='AE2 loss')\n",
        "plt.plot(history2.history['val_loss'],'m',label='AE2 val loss')\n",
        "plt.plot(history3.history['loss'],'r',label='AE3 loss')\n",
        "plt.plot(history3.history['val_loss'],'b',label='AE3 val loss')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(loc='upper right')\n",
        "plt.savefig('stackAEwhole_model_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEcd0OuRfjxx"
      },
      "source": [
        "stackautoencoder.layers[1].set_weights(autoencoder1.layers[1].get_weights()) # first dense layer\n",
        "stackautoencoder.layers[2].set_weights(autoencoder1.layers[2].get_weights())\n",
        "stackautoencoder.layers[3].set_weights(autoencoder2.layers[1].get_weights())\n",
        "stackautoencoder.layers[4].set_weights(autoencoder2.layers[2].get_weights())\n",
        "stackautoencoder.layers[5].set_weights(autoencoder3.layers[1].get_weights())\n",
        "stackautoencoder.layers[6].set_weights(autoencoder3.layers[2].get_weights())\n",
        "stackautoencoder.layers[7].set_weights(autoencoder3.layers[3].get_weights())\n",
        "stackautoencoder.layers[8].set_weights(autoencoder3.layers[4].get_weights())\n",
        "stackautoencoder.layers[9].set_weights(autoencoder2.layers[3].get_weights())\n",
        "stackautoencoder.layers[10].set_weights(autoencoder2.layers[4].get_weights())\n",
        "stackautoencoder.layers[11].set_weights(autoencoder1.layers[3].get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzC6wvRlfkRP"
      },
      "source": [
        "evaluation = stackautoencoder.evaluate(x_test, x_test)\n",
        "print(\"Loss:\",evaluation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYqqKCXSfla3"
      },
      "source": [
        "stackencoder = Model(input_data, encoded)\n",
        "latent_vector_train = stackencoder.predict(x_train)\n",
        "latent_vector = stackencoder.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4aVJGl9fmlt"
      },
      "source": [
        "latent_vector.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yGvNcGufnsl"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knnscores = []\n",
        "for i in range(1,10):\n",
        "    knn = KNeighborsClassifier(n_neighbors = i)\n",
        "    knn.fit(latent_vector_train, y_train)\n",
        "    k = knn.score(latent_vector,y_test)\n",
        "    knnscores.append(k)\n",
        "\n",
        "s = np.array(knnscores)\n",
        "result = np.where(s == s.max())\n",
        "print('Knn Score : ',s.max(),'and k : ', result[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OYSX63_fo8i"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = knn.predict(latent_vector)\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7W4lCKCfqOR"
      },
      "source": [
        "latent_vector_train = np.load('/content/latent_vector_train.npy')\n",
        "latent_vector = np.load('/content/latent_vector.npy')\n",
        "y_train = np.load('/content/y_train.npy')\n",
        "y_test = np.load('/content/y_test.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6MHU1af1qH"
      },
      "source": [
        "train_df = pd.DataFrame(latent_vector_train)\n",
        "train_df['flag'] = y_train\n",
        "test_df = pd.DataFrame(latent_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Cj8KXvf2ph"
      },
      "source": [
        "!pip install ctgan #https://sdv.dev/SDV/user_guides/single_table/ctgan.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U-jB57yf36P"
      },
      "source": [
        "from ctgan import CTGANSynthesizer\n",
        "ctgan = CTGANSynthesizer()\n",
        "ctgan.fit(train_df, discrete_columns=['flag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R81luqKvf45x"
      },
      "source": [
        "samples = ctgan.sample(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCfeQkLMgFW5"
      },
      "source": [
        "ctgan_result_df = pd.concat([train_df,samples])\n",
        "ctgan_result_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8hCu_9gGt4"
      },
      "source": [
        "y_train_ctgan = ctgan_result_df['flag']\n",
        "X_train_ctgan = ctgan_result_df.drop('flag', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}