{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Soft Voting Ensemble.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hGgsbAlg3Fo"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import seaborn as sn \n",
        "from seaborn import distplot\n",
        "from seaborn import heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from math import isinf \n",
        "from scipy.interpolate import interp1d\n",
        "from numpy import array, zeros, full, argmin, inf, ndim\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "import statistics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier as RB\n",
        "#from sklearn.decomposition import KernelPCA\n",
        "#from imblearn.over_sampling import SMOTE as SM\n",
        "from sklearn.ensemble import RandomForestClassifier as RF,GradientBoostingRegressor as GB,ExtraTreesClassifier as ET\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.neural_network import MLPClassifier as MP\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        " \n",
        "# Scikit-Learn imports\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTZYmPeFjiDU",
        "outputId": "486c5359-8111-4c4c-9b03-2cea078ff533"
      },
      "source": [
        "!pip install -q shap"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 102 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 143 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 163 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 174 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 194 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 204 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 215 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 225 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 235 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 245 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 256 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 276 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 286 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 296 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 307 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 317 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 327 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 337 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 348 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 356 kB 6.7 MB/s \n",
            "\u001b[?25h  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InXi7nQjjiWD",
        "outputId": "b23f574e-2134-444a-e010-e93bdf214712"
      },
      "source": [
        "!pip install -q eli5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 106 kB 8.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLHFaOM4jjLi",
        "outputId": "f03a48ca-ad24-4c95-f315-0b4b3dbb0158"
      },
      "source": [
        "import shap\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.inspection import plot_partial_dependence\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_curve, roc_auc_score, roc_curve, f1_score, auc"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOMuZJgAjkky"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [0.1, 0.2, 0.25, 0.3, 1],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 500, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestClassifier()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 10, n_jobs = -1, verbose = 2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nxovk0okIdG"
      },
      "source": [
        "#grid_search.fit(X_train_ctgan, y_train_ctgan)\n",
        "#grid_search.best_params_\n",
        "#best_grid = grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmceSkjTkft1"
      },
      "source": [
        "estimator = xgb.XGBClassifier(\n",
        "    objective= 'binary:logistic',\n",
        "    nthread=4,\n",
        "    random_state = 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDkCZSnDl3x_"
      },
      "source": [
        "parameters = {\n",
        "    'max_depth': [0.2, 0.4, 0.6, 0.8, 1],\n",
        "    'n_estimators': [100, 200, 400, 500, 800],\n",
        "    'learning_rate': [0.1, 0.01, 0.03, 0.07, 0.1]\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK8ZRfWImICo"
      },
      "source": [
        "grid_search = GridSearchCV(\n",
        "    estimator=estimator,\n",
        "    param_grid=parameters,\n",
        "    scoring = 'roc_auc',\n",
        "    n_jobs = 10,\n",
        "    cv = 10,\n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIViIpltmPfc"
      },
      "source": [
        "#grid_search.fit(X_train_ctgan, y_train_ctgan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfijOc7ImapZ"
      },
      "source": [
        "grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j8-gHhGmdmn"
      },
      "source": [
        "rnd_fr_clf = RandomForestClassifier(n_estimators=500,\n",
        "                                max_features=0.25,\n",
        "                                criterion=\"entropy\",\n",
        "                                class_weight=\"balanced\",\n",
        "                                random_state=1)\n",
        "\n",
        "scores = cross_val_score(rnd_fr_clf,\n",
        "                         X_train_ctgan, \n",
        "                         y_train_ctgan,\n",
        "                         scoring=\"roc_auc\", \n",
        "                         cv=10, \n",
        "                         n_jobs=-1, \n",
        "                         verbose=50)\n",
        "print(\"Baseline model (RandomForest) Mean AUC:\", scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUJ-RBcqmpD3"
      },
      "source": [
        "#train_acc = rnd_fr_clf.score(latent_vector_train, y_train)\n",
        "# y_pred = rnd_fr_clf.predict(x_test)\n",
        "# test_acc = accuracy_score(y_test, y_pred)\n",
        "# print(train_acc,test_acc)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "rnd_fr_clf.fit(latent_vector_train, y_train)\n",
        "# predict probabilities\n",
        "probs = rnd_fr_clf.predict_proba(latent_vector)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs = probs[:, 1]\n",
        "# predict class values\n",
        "# y_pred = rnd_fr_clf.predict(x_test)\n",
        "\n",
        "# plot the ROC curve\n",
        "rnd_fr_fpr, rnd_fr_tpr, rnd_fr_th = roc_curve(y_test, probs)\n",
        "ax[0].plot(rnd_fr_fpr, rnd_fr_tpr, label='Baseline Random Forest')\n",
        "ax[0].set_xlabel(\"False Positive\")\n",
        "ax[0].set_ylabel(\"True Positive\")\n",
        "ax[0].legend()\n",
        "ax[0].set_title(\"ROC curve\")\n",
        "# plot the precision-recall curve\n",
        "rnd_fr_precision, rnd_fr_recall, _ = precision_recall_curve(y_test, probs)\n",
        "ax[1].plot(rnd_fr_recall, rnd_fr_precision, label='Baseline Random Forest')\n",
        "ax[1].set_xlabel('Recall')\n",
        "ax[1].set_ylabel('Precision')\n",
        "ax[1].legend()\n",
        "ax[1].set_title(\"Precision Recall curve\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oN1958jmrTr"
      },
      "source": [
        "# Define base learners\n",
        "rnd_fr_clf = RandomForestClassifier(n_estimators=300,\n",
        "                                max_features=\"sqrt\",\n",
        "                                criterion=\"gini\",\n",
        "                                min_samples_leaf=5,\n",
        "                                class_weight=\"balanced\",\n",
        "                                random_state=1)\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
        "                            learning_rate=0.03,\n",
        "                            n_estimators=500,\n",
        "                            max_depth=1,\n",
        "                            subsample=0.4,\n",
        "                            random_state=1)\n",
        "\n",
        "# Define meta-learner\n",
        "logreg_clf = LogisticRegression(penalty=\"l2\",\n",
        "                                C=100,\n",
        "                                fit_intercept=True)\n",
        "\n",
        "# average ensemble\n",
        "voting_clf = VotingClassifier([(\"xgb\", xgb_clf),\n",
        "                               (\"rf\", rnd_fr_clf)],\n",
        "                              voting=\"soft\",\n",
        "                              flatten_transform=True)\n",
        "voting_clf.fit(latent_vector_train, y_train)\n",
        "xgb_model, rf_model = voting_clf.estimators_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzTjJe_1mvXf"
      },
      "source": [
        "models = {\"xgb\": xgb_model, \"rf\": rf_model, \"avg_ensemble\": voting_clf}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NWYXOL3mv8z"
      },
      "source": [
        "# Build first stack of base learners\n",
        "average_ensemble = make_pipeline(voting_clf,\n",
        "                            FunctionTransformer(lambda X: X[:, 1::2]))\n",
        "# Use CV to generate meta-features\n",
        "meta_features = cross_val_predict(average_ensemble,\n",
        "                                  X_train_ctgan,y_train_ctgan,\n",
        "                                  cv=10,\n",
        "                                  method=\"transform\",\n",
        "                                  n_jobs=-1,\n",
        "                                  verbose=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mI8n1wMm8-N"
      },
      "source": [
        "# Refit the first stack on the full training set\n",
        "average_ensemble.fit(X_train_ctgan,y_train_ctgan)\n",
        "# Fit the meta learner\n",
        "stacked_ensemble = logreg_clf.fit(meta_features, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nvoaWfCnHos"
      },
      "source": [
        "# Plot ROC and PR curves using all models and test data\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "for name, model in models.items():\n",
        "    model_probs = model.predict_proba(latent_vector)[:, 1:]\n",
        "    model_auc_score = roc_auc_score(y_test, model_probs)\n",
        "    fpr, tpr, th = roc_curve(y_test, model_probs)\n",
        "    precision, recall, _ = precision_recall_curve(y_test, model_probs)\n",
        "    ax[0].plot(fpr, tpr, label=name + str(model_auc_score))\n",
        "    ax[1].plot(recall, precision, label=name)\n",
        "\n",
        "stacked_probs = stacked_ensemble.predict_proba(average_ensemble.transform(latent_vector))[:, 1:]\n",
        "stacked_auc_score = roc_auc_score(y_test, stacked_probs)\n",
        "fpr, tpr, th = roc_curve(y_test, stacked_probs)\n",
        "ax[0].plot(fpr, tpr, label=\"stacked_ensemble\"+ str(stacked_auc_score))\n",
        "ax[0].set_xlabel(\"False Positive\")\n",
        "ax[0].set_ylabel(\"True Positive\")\n",
        "ax[0].legend()\n",
        "ax[0].set_title(\"ROC curve\")\n",
        "ax[1].set_xlabel('Recall')\n",
        "ax[1].set_ylabel('Precision')\n",
        "ax[1].legend()\n",
        "ax[1].set_title(\"Precision Recall curve\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFkMX2rFnhm-"
      },
      "source": [
        "y_prob= stacked_ensemble.predict_proba(average_ensemble.transform(latent_vector))[:, 1:]\n",
        "y_pred= stacked_ensemble.predict(average_ensemble.transform(latent_vector))\n",
        "print('Confusion Matrix')\n",
        "print('='*60)\n",
        "print(confusion_matrix(y_test,y_pred),\"\\n\")\n",
        "print('Classification Report')\n",
        "print('='*60)\n",
        "print(classification_report(y_test,y_pred),\"\\n\")\n",
        "print('AUC-ROC')\n",
        "print('='*60)\n",
        "print(roc_auc_score(y_test, y_prob))\n",
        "print(precision_score(y_test,y_pred))\n",
        "print(recall_score(y_test,y_pred))\n",
        "print(f1_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCUf50rAnjeK"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_corrcoef(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUQw5qeMnj78"
      },
      "source": [
        "from sklearn.metrics import auc, plot_precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "# Use AUC function to calculate the area under the curve of precision recall curve\n",
        "auc_precision_recall = auc(recall, precision)\n",
        "print(auc_precision_recall)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}